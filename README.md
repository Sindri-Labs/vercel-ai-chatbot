# Vercel AI Chatbot
This is a clone of [Vercel's AI Chatbot](https://vercel.com/templates/next.js/nextjs-ai-chatbot) at commit [7d8e713](https://github.com/vercel/ai-chatbot/tree/7d8e71383f55c766ca575da2cac0a8d89283c031).

## Running locally


### Requirements
- [Docker](https://www.docker.com/get-started/)


### 1. Clone the Repo
```bash
git clone git@github.com:Sindri-Labs/vercel-ai-chatbot.git
cd vercel-ai-chatbot
```

### 2. Setup (Run with Sindri)
Configure your environment variable file that will be used with Docker Compose:
```bash
cp .env.example.sindri .env
```
Then, edit your new `.env` file. Fill out the `OPENAI_API_KEY` variable with your Sindri API Key. A Sindri API Key can be generated by first [creating a Sindri account](https://sindri.app/signup) then visiting the [API Keys page](https://sindri.app/z/me/page/settings/api-keys).


### 3. Run
Build and run the application:
```bash
docker compose --env-file .env up --build
```


### 4. Visit the Site and Start Chatting!
Visit [http://localhost:3000](http://localhost:3000) and start chatting as a *guest* user.
Chat history will not be saved between sessions.

Notes:
- All chats are automatically encrypted with Sindri's Trusted Execution Environment (TEE)! *The console logs for the `evllmp` container show encrypted/decrypted chats.*
- Sindri is still in development. File uploads and web searches are still in development and currently do not work.


### 5 (Optional). Create an Account and Log in to Save your Chat History
Visit [http://localhost:3000/register](http://localhost:3000/register) and create an account.

You can also visit the Account menu in the bottom of the left sidebar. Here you can create accounts and log into existing accounts.


### 6. Stop
To bring it all down, run:
```bash
docker compose down
```

You can bring it up again with `docker compose --env-file .env up`. This will skip the building phase and existing accounts and their chat histories will be restored.


# Other

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `AUTH_SECRET` | JWT encryption secret | ***Required*** (create with `openssl rand -base64 32`) |
| `BLOB_READ_WRITE_TOKEN` | Vercel Blob Storage key | ***Required*** |
| `MAX_COMPLETION_TOKENS` | Maximum tokens for responses | `1000` |
| `OPENAI_API_KEY` | Your OpenAI API key | ***Required*** |
| `OPENAI_BASE_URL` | Custom OpenAI-compatible endpoint | `https://api.openai.com/v1` |
| `OPENAI_MODEL` | Model to use for chat completions | `gpt-4o-mini` |
| `PORT` | Port the server is exposed | `3000` |
| `SINDRI_BASE_URL` | Sindri OpenAI-compatible endpoint | `https://sindri.app/api/ai/v1/openai` |
| `USE_TOOLS` | Enable AI tools (weather, documents, etc.) | `false` |

## Key Modifications

- **Docker Deployment**: Complete containerized setup with PostgreSQL and Redis
- **OpenAI Integration**: Switched from xAI to OpenAI with configurable base URL
- **PDF Support**: Added PDF and JSON file upload support (up to 100MB)
- **Authentication**: Fixed auth flow and added guest mode
- **Environment Variables**: All configuration via Docker environment variables
- This Vercel version still uses the OpenAI `/v1/chat/completions` instead of the newer `/v1/responses` endpoint. Sindri does not yet support `/v1/responses`.

